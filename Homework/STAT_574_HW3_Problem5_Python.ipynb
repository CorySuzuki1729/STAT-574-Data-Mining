{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\coryg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\coryg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "c:\\Users\\coryg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses\\losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0000e+00\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Accuracy: 0.4571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\coryg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# STAT 574 HW3 Problem 5\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "from statistics import mean\n",
    "\n",
    "concussion_data = pd.read_csv(\"C:/Users/coryg/OneDrive/Desktop/STAT_574_Data_Mining/concussions_data.csv\")\n",
    "position_code = {'Offensive Lineman':0, 'Cornerback':1, 'Running Back':2, 'Quarterback':3, 'Wide Receiver':4}\n",
    "concussion_code = {'mild':0, 'moderate':1, 'severe':2}\n",
    "concussion_data['position'] = concussion_data['position'].map(position_code)\n",
    "concussion_data['concussion'] = concussion_data['concussion'].map(concussion_code)\n",
    "X = concussion_data.drop(['concussion'], axis=1)\n",
    "y = concussion_data.drop(['age', 'nyearsplaying', 'position', 'prevconc'], axis=1)\n",
    "\n",
    "# Scaling the data to fall within [0, 1]. \n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler_fit = scaler.fit_transform(X)\n",
    "scaled_concussion = pd.DataFrame(scaler_fit, columns=['age', 'nyearsplaying', 'position', 'prevconc'])\n",
    "new_data = pd.concat([scaled_concussion, y], axis=1)\n",
    "\n",
    "# Splitting data into 80% training and 20% testing sets. \n",
    "\n",
    "X = new_data.iloc[:, 0:4].values\n",
    "y = new_data.iloc[:, 4].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,\n",
    "                                random_state=123055)\n",
    "\n",
    "# Constructing ANN model for multinomial classification. Using the sigmoid \n",
    "# activation function in the output layer. \n",
    "\n",
    "tf.random.set_seed(210572)\n",
    "\n",
    "sigmoid_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, activation=\"relu\", input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(1, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "sigmoid_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      loss=['categorical_crossentropy'])\n",
    "\n",
    "sigmoid_model.fit(X_train, y_train)\n",
    "\n",
    "# Computing prediction accuracy for testing data. \n",
    "\n",
    "sigmoid_prob = sigmoid_model.predict(X_test)\n",
    "sigmoid_pred = pd.DataFrame(sigmoid_prob, columns=['predicted'])\n",
    "y_test = pd.DataFrame(y_test, columns=['concussion'])\n",
    "df = pd.concat([sigmoid_pred, y_test], axis=1)\n",
    "match = []\n",
    "for i in range(len(df)):\n",
    "    if df['concussion'][i] == df['predicted'][i]:\n",
    "        match.append(1)\n",
    "    else:\n",
    "        match.append(0)\n",
    "\n",
    "print(\"Accuracy:\", round(mean(match), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\coryg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\coryg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "c:\\Users\\coryg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses\\losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0000e+00\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Accuracy: 0.4571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\coryg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Constructing ANN model for multinomial classification. Using the tanh \n",
    "# activation function in the output layer. \n",
    "\n",
    "tf.random.set_seed(622904)\n",
    "\n",
    "tanh_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, activation=\"tanh\", input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(1, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "tanh_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      loss=['categorical_crossentropy'])\n",
    "\n",
    "tanh_model.fit(X_train, y_train)\n",
    "\n",
    "# Computing prediction accuracy for testing data. \n",
    "\n",
    "tanh_pred = pd.DataFrame(tanh_model.predict(X_test), columns=['predicted'])\n",
    "y_test = pd.DataFrame(y_test, columns=['concussion'])\n",
    "df2 = pd.concat([tanh_pred, y_test], axis=1)\n",
    "match2 = []\n",
    "for i in range(len(df2)):\n",
    "    if df2['concussion'][i] == df2['predicted'][i]:\n",
    "        match2.append(1)\n",
    "    else:\n",
    "        match2.append(0)\n",
    "\n",
    "print(\"Accuracy:\", round(mean(match2), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
